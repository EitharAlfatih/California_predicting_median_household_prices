}
# drop all rows with NA values
if(drop_na_rows == TRUE) {
data <- data %>% drop_na()
} else {
data <- data
}
return(data)
}
clean_data <- function(file_path = filepath,
skip_rows = rows_to_skip,           # default will be 0
drop_na_rows = TRUE)
{
# load the data into this script - choice to skip rows
if(skip_rows > 0) {
data <- readr::read_csv(file_path, skip = skip_rows)
} else {
data <- readr::read_csv(file_path)
}
# drop all rows with NA values
if(drop_na_rows == TRUE) {
data <- data %>% drop_na()
} else {
data <- data
}
return(data)
}
# Split data into X and y and complete relevant wrangling
data %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_housing_value)
# Split data into X and y and complete relevant wrangling
data %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
clean_data <- function(file_path_in = filepath_in,        # no default
drop_na_rows = TRUE,               # default will be TRUE
file_path_out_train = filepath_out_train,      # no default
file_path_out_test = filepath_out_test)
{
# load the data into this script
data <- readr::read_csv(file_path_in, skip = skip_rows)
# drop all rows with NA values - choice
if(drop_na_rows == TRUE) {
data <- data %>% drop_na()
} else {
data <- data
}
# Split data into X and y and complete relevant wrangling
data %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
return(data)
}
clean_data()
filepath_in <- 'data.csv'
filepath_in <- 'data.csv'
rows_to_skip <- 1
filepath_out_train <- 'train.csv'
filepath_out_test <- 'test.csv'
clean_data <- function(file_path_in = filepath_in,        # no default
drop_na_rows = TRUE,               # default will be TRUE
file_path_out_train = filepath_out_train,      # no default
file_path_out_test = filepath_out_test)
{
# load the data into this script
data <- readr::read_csv(file_path_in, skip = skip_rows)
# drop all rows with NA values - choice
if(drop_na_rows == TRUE) {
data <- data %>% drop_na()
} else {
data <- data
}
# Split data into X and y and complete relevant wrangling
data %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
return(data)
}
clean_data()
# load the data into this script
data <- readr::read_csv(file_path_in, skip = 1)
filepath_in <- 'data.csv'
rows_to_skip <- 1
filepath_out_train <- 'train.csv'
filepath_out_test <- 'test.csv'
clean_data <- function(file_path_in = filepath_in,        # no default
drop_na_rows = TRUE,               # default will be TRUE
file_path_out_train = filepath_out_train,      # no default
file_path_out_test = filepath_out_test)
{
# load the data into this script
data <- readr::read_csv(file_path_in, skip = 1)
# drop all rows with NA values - choice
if(drop_na_rows == TRUE) {
data <- data %>% drop_na()
} else {
data <- data
}
# Split data into X and y and complete relevant wrangling
data %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
return(data)
}
clean_data()
return(data)
filepath_in <- 'data.csv'
rows_to_skip <- 1
filepath_out_train <- 'train.csv'
filepath_out_test <- 'test.csv'
clean_data <- function(file_path_in = filepath_in,        # no default
drop_na_rows = TRUE,               # default will be TRUE
file_path_out_train = filepath_out_train,      # no default
file_path_out_test = filepath_out_test)
{
# load the data into this script
data <- readr::read_csv(file_path_in, skip = 1)
# drop all rows with NA values - choice
if(drop_na_rows == TRUE) {
data <- data %>% drop_na()
} else {
data <- data
}
# Split data into X and y and complete relevant wrangling
data <- data %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
return(data)
}
clean_data()
install.packages("caTools")
library(tidyverse)
library(readr)
library(tidyr)
library(caTools)
filepath_in <- 'data.csv'
rows_to_skip <- 1
filepath_out_train <- 'train.csv'
filepath_out_test <- 'test.csv'
clean_data <- function(file_path_in = filepath_in,        # no default
drop_na_rows = TRUE,               # default will be TRUE
file_path_out_train = filepath_out_train,      # no default
file_path_out_test = filepath_out_test)
{
# load the data into this script
data <- readr::read_csv(file_path_in, skip = 1)
# drop all rows with NA values - choice
if(drop_na_rows == TRUE) {
data <- data %>% drop_na()
} else {
data <- data
}
# Complete Wrangling
data <- data %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
# Split into training and testing data
set.seed(522)
return(data)
}
clean_data()
library(tidyverse)
library(readr)
library(tidyr)
library(caTools)
filepath_in <- 'data.csv'
rows_to_skip <- 1
filepath_out_train <- 'train.csv'
filepath_out_test <- 'test.csv'
clean_data <- function(file_path_in = filepath_in,        # no default
drop_na_rows = TRUE,               # default will be TRUE
file_path_out_train = filepath_out_train,      # no default
file_path_out_test = filepath_out_test)
{
# load the data into this script
data <- readr::read_csv(file_path_in, skip = 1)
# drop all rows with NA values - choice
if(drop_na_rows == TRUE) {
data <- data %>% drop_na()
} else {
data <- data
}
# Complete Wrangling
data <- data %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
# Split into training and testing data
set.seed(522)
return(data)
}
data %>% head()
clean_data()
data <- clean_data()
train <- subset(data, sample == TRUE)
library(caret)
set.seed(1)
trainindex <- createDataPartition(y = data$median_house_value, times = 1, p = 0.8)
train <- data[trainindex,]
trainindex <- createDataPartition(y = data$median_house_value, times = 1, p = 0.8, list = FALSE)
train <- data[trainindex,]
test <- data[-trainindex,]
library(tidyverse)
library(readr)
library(tidyr)
library(caret)
filepath_in <- 'data.csv'
rows_to_skip <- 1
filepath_out_train <- 'train.csv'
filepath_out_test <- 'test.csv'
clean_data <- function(file_path_in = filepath_in,        # no default
file_path_out_train = filepath_out_train,      # no default
file_path_out_test = filepath_out_test)
{
# load the data into this script
data <- readr::read_csv(file_path_in, skip = 1)
# drop all rows with NA values - choice
if(drop_na_rows == TRUE) {
data <- data %>% drop_na()
} else {
data <- data
}
# Complete Wrangling
data <- data %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
# Split into training and testing data
set.seed(522)
trainindex <- createDataPartition(y = data$median_house_value, times = 1, p = 0.8, list = FALSE)
train <- data[trainindex,]
test <- data[-trainindex,]
readr::write_csv(x = train, path = file_path_out_train)
readr::write_csv(x = test, path = file_path_out_test)
}
clean_data()
clean_data <- function(file_path_in = filepath_in,        # no default
file_path_out_train = filepath_out_train,      # no default
file_path_out_test = filepath_out_test)
{
# load the data into this script
data <- readr::read_csv(file_path_in, skip = 1)
# Complete Wrangling
data <- data %>%
drop_na() %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
# Split into training and testing data
set.seed(522)
trainindex <- createDataPartition(y = data$median_house_value, times = 1, p = 0.8, list = FALSE)
train <- data[trainindex,]
test <- data[-trainindex,]
readr::write_csv(x = train, path = file_path_out_train)
readr::write_csv(x = test, path = file_path_out_test)
}
filepath_in <- 'data.csv'
rows_to_skip <- 1
filepath_out_train <- 'train.csv'
filepath_out_test <- 'test.csv'
clean_data()
setwd("~/Documents/MDS/DSCI_522/class_scripts")
citation()
citation("tidyverse")
citation("readr")
citation("tidyr")
citation(caret)
citation("caret")
setwd("~/Documents/MDS/DSCI_522/DSCI_522_GROUP_312")
citation("docopt")
setwd("~/Documents/MDS/DSCI_522/DSCI_522_GROUP_312/scripts")
"This script takes in a filepath to a CSV, performs relevant wrangling,
and then splits the CSV into training and testing data, and then saves
training and testing data as CSVs to respective specified filepaths.
Usage: Rscript wrangle-and-split-data.R --filepath_in=<filepath_in> --filepath_out_train=<filepath_out_train> --filepath_out_test=<filepath_out_test>
" -> doc
"This script takes in a filepath to a CSV, performs relevant wrangling,
and then splits the CSV into training and testing data, and then saves
training and testing data as CSVs to respective specified filepaths.
Usage: Rscript wrangle-and-split-data.R --filepath_in=<filepath_in> --filepath_out_train=<filepath_out_train> --filepath_out_test=<filepath_out_test>
" -> doc
"This script takes in a filepath to a CSV, performs relevant wrangling,
and then splits the CSV into training and testing data, and then saves
training and testing data as CSVs to respective specified filepaths.
Usage: wrangle-and-split-data.R --filepath_in=<filepath_in> --filepath_out_train=<filepath_out_train> --filepath_out_test=<filepath_out_test>
" -> doc
readr::write_csv(x = test, path = file_path_out_test)
train <- data[trainindex,]
# author: DSCI 522 Group 312
# date: 2020-01-22
"This script takes in a filepath to a CSV, performs relevant wrangling,
and then splits the CSV into training and testing data, and then saves
training and testing data as CSVs to respective specified filepaths.
Usage: wrangle-and-split-data.R --filepath_in=<filepath_in> --filepath_out_train=<filepath_out_train> --filepath_out_test=<filepath_out_test>
Options:
--file_path_in=<file_path_in>   Path (including filename) to source data file (from load_data.py)
--file_path_out_train=<file_path_out_train>   Path (including filename) to where the training data should be saved
--file_path_out_test=<file_path_out_test>   Path (including filename) to where the testing data should be saved
" -> doc
library(tidyverse)
library(readr)
library(tidyr)
library(caret)
library(docopt)
opt <- docopt(doc)
main <- function(file_path_in, file_path_out_train, file_path_out_test) {
# load the data into this script
data <- readr::read_csv(file_path_in, skip = 1)
# Complete Wrangling
data <- data %>%
drop_na() %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
# Split into training and testing data
set.seed(522)
trainindex <- createDataPartition(y = data$median_house_value, times = 1, p = 0.8, list = FALSE)
train <- data[trainindex,]
test <- data[-trainindex,]
readr::write_csv(x = train, path = file_path_out_train)
readr::write_csv(x = test, path = file_path_out_test)
}
main(opt[["--file_path_in"]], opt[["--file_path_out_train"]], opt[["--file_path_out_test"]])
# References
# Balla, Deepanshu. n.d. SPLITTING Data into Training and Test Sets with R. https://www.listendata.com/2015/02/splitting-data-into-training-and-test.html.
#
# de Jonge, Edwin 2018. docopt: Command-Line Interface Specification Language. https://CRAN.R-project.org/package=docopt.
#
# Kuhn, Max. 2020. Caret: Classification and Regression Training. https://CRAN.R-project.org/package=caret.
#
# R Core Team. 2019. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.
#
# Wickham, Hadley. 2017. Tidyverse: Easily Install and Load the ’Tidyverse’. https://CRAN.R-project.org/package=tidyverse.
#
# Wickham, Hadley, and Lionel Henry. 2019. Tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr.
#
# Wickham, Hadley, Jim Hester, and Romain Francois. 2018. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.
library(docopt)
library(docopt)
# author: DSCI 522 Group 312
# date: 2020-01-22
"This script takes in a filepath to a CSV, performs relevant wrangling,
and then splits the CSV into training and testing data, and then saves
training and testing data as CSVs to respective specified filepaths.
Usage: wrangle-and-split-data.R --filepath_in=<filepath_in> --filepath_out_train=<filepath_out_train> --filepath_out_test=<filepath_out_test>
Options:
--file_path_in=<file_path_in>   Path (including filename) to source data file (from load_data.py)
--file_path_out_train=<file_path_out_train>   Path (including filename) to where the training data should be saved
--file_path_out_test=<file_path_out_test>   Path (including filename) to where the testing data should be saved
" -> doc
library(tidyverse)
library(readr)
library(tidyr)
library(caret)
library(docopt)
opt <- docopt(doc)
main <- function(file_path_in, file_path_out_train, file_path_out_test) {
# load the data into this script
data <- readr::read_csv(file_path_in, skip = 1)
# Complete Wrangling
data <- data %>%
drop_na() %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
# Split into training and testing data
set.seed(522)
trainindex <- createDataPartition(y = data$median_house_value, times = 1, p = 0.8, list = FALSE)
train <- data[trainindex,]
test <- data[-trainindex,]
readr::write_csv(x = train, path = file_path_out_train)
readr::write_csv(x = test, path = file_path_out_test)
}
main(opt[["--file_path_in"]], opt[["--file_path_out_train"]], opt[["--file_path_out_test"]])
)
opt <- docopt(doc)
opt <- docopt(doc)
main(opt[["--filepath_in"]], opt[["--filepath_out_train"]], opt[["--filepath_out_test"]])
# author: DSCI 522 Group 312
# date: 2020-01-22
"This script takes in a filepath to a CSV, performs relevant wrangling,
and then splits the CSV into training and testing data, and then saves
training and testing data as CSVs to respective specified filepaths.
Usage: wrangle-and-split-data.R --filepath_in=<filepath_in> --filepath_out_train=<filepath_out_train> --filepath_out_test=<filepath_out_test>
Options:
--filepath_in=<filepath_in>   Path (including filename) to source data file (from load_data.py)
--filepath_out_train=<filepath_out_train>   Path (including filename) to where the training data should be saved
--filepath_out_test=<filepath_out_test>   Path (including filename) to where the testing data should be saved
" -> doc
library(tidyverse)
library(readr)
library(tidyr)
library(caret)
library(docopt)
opt <- docopt(doc)
main <- function(filepath_in, filepath_out_train, filepath_out_test) {
# load the data into this script
data <- readr::read_csv(filepath_in, skip = 1)
# Complete Wrangling
data <- data %>%
drop_na() %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
# Split into training and testing data
set.seed(522)
trainindex <- createDataPartition(y = data$median_house_value, times = 1, p = 0.8, list = FALSE)
train <- data[trainindex,]
test <- data[-trainindex,]
readr::write_csv(x = train, path = filepath_out_train)
readr::write_csv(x = test, path = filepath_out_test)
}
main(opt[["--filepath_in"]], opt[["--filepath_out_train"]], opt[["--filepath_out_test"]])
# References
# Balla, Deepanshu. n.d. SPLITTING Data into Training and Test Sets with R. https://www.listendata.com/2015/02/splitting-data-into-training-and-test.html.
#
# de Jonge, Edwin 2018. docopt: Command-Line Interface Specification Language. https://CRAN.R-project.org/package=docopt.
#
# Kuhn, Max. 2020. Caret: Classification and Regression Training. https://CRAN.R-project.org/package=caret.
#
# R Core Team. 2019. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.
#
# Wickham, Hadley. 2017. Tidyverse: Easily Install and Load the ’Tidyverse’. https://CRAN.R-project.org/package=tidyverse.
#
# Wickham, Hadley, and Lionel Henry. 2019. Tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr.
#
# Wickham, Hadley, Jim Hester, and Romain Francois. 2018. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.
"This script takes in a filepath to a CSV, performs relevant wrangling,
and then splits the CSV into training and testing data, and then saves
training and testing data as CSVs to respective specified filepaths.
Usage: scripts/wrangle-and-split-data.R --filepath_in=<filepath_in> --filepath_out_train=<filepath_out_train> --filepath_out_test=<filepath_out_test>
Options:
--filepath_in=<filepath_in>   Path (including filename) to source data file (from load_data.py)
--filepath_out_train=<filepath_out_train>   Path (including filename) to where the training data should be saved
--filepath_out_test=<filepath_out_test>   Path (including filename) to where the testing data should be saved
" -> doc
install.packages("checkmate")
setwd("~/Documents/MDS/DSCI_522/DSCI_522_GROUP_312")
library(checkmate)
checkFileExists(x = 'test.csv')
citation("checkmate")
test_files_created()
main(opt[["--filepath_in"]], opt[["--filepath_out_train"]], opt[["--filepath_out_test"]])
# author: DSCI 522 Group 312
# date: 2020-01-22
"This script takes in a filepath to a CSV, performs relevant wrangling,
and then splits the CSV into training and testing data, and then saves
training and testing data as CSVs to respective specified filepaths.
Usage: scripts/wrangle-and-split-data.R --filepath_in=<filepath_in> --filepath_out_train=<filepath_out_train> --filepath_out_test=<filepath_out_test>
Options:
--filepath_in=<filepath_in>   Path (including filename) to source data file (from load_data.py)
--filepath_out_train=<filepath_out_train>   Path (including filename) to where the training data should be saved
--filepath_out_test=<filepath_out_test>   Path (including filename) to where the testing data should be saved
" -> doc
library(tidyverse)
library(readr)
library(tidyr)
library(caret)
library(docopt)
opt <- docopt(doc)
main <- function(filepath_in, filepath_out_train, filepath_out_test) {
# load the data into this script
data <- readr::read_csv(filepath_in, skip = 1)
# Complete Wrangling
data <- data %>%
drop_na() %>%
mutate(median_income = median_income * 10000) %>%
select(housing_median_age, total_rooms, total_bedrooms, population, households,
median_income, ocean_proximity, latitude, longitude, median_house_value)
# Split into training and testing data
set.seed(522)
trainindex <- createDataPartition(y = data$median_house_value, times = 1, p = 0.8, list = FALSE)
train <- data[trainindex,]
test <- data[-trainindex,]
readr::write_csv(x = train, path = filepath_out_train)
readr::write_csv(x = test, path = filepath_out_test)
}
test_files_created <- function() {
if (checkFileExists(x = filepath_out_train) == TRUE &
checkFileExists(x = filepath_out_test) == TRUE) {
print("Training and Testing files successfully created and saved")
} else {
print("There was an issue creating Training and Testing files. Please try again.")
}
}
test_files_created()
main(opt[["--filepath_in"]], opt[["--filepath_out_train"]], opt[["--filepath_out_test"]])
# References
# Balla, Deepanshu. n.d. SPLITTING Data into Training and Test Sets with R. https://www.listendata.com/2015/02/splitting-data-into-training-and-test.html.
#
# de Jonge, Edwin 2018. docopt: Command-Line Interface Specification Language. https://CRAN.R-project.org/package=docopt.
#
# Kuhn, Max. 2020. Caret: Classification and Regression Training. https://CRAN.R-project.org/package=caret.
#
# Lang, Michael 2017. checkmate: Fast Argument Checks for Defensive R Programming. https://journal.r-project.org/archive/2017/RJ-2017-028/index.html.
#
# R Core Team. 2019. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.
#
# Wickham, Hadley. 2017. Tidyverse: Easily Install and Load the ’Tidyverse’. https://CRAN.R-project.org/package=tidyverse.
#
# Wickham, Hadley, and Lionel Henry. 2019. Tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr.
#
# Wickham, Hadley, Jim Hester, and Romain Francois. 2018. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.
citation("testthat")
